apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: vllm-queue-scaler
  namespace: default
spec:
  scaleTargetRef:
    name: vllm
  minReplicaCount: 1
  maxReplicaCount: 10
  pollingInterval: 2          # Poll every 2 seconds for faster reaction
  cooldownPeriod: 300
  triggers:
  - type: kedify-otel
    name: running
    metadata:
      scalerAddress: 'kedify-otel-scaler.keda.svc:4318'
      metricQuery: 'sum(vllm_num_requests_running)'
      targetValue: '25'       # Each pod handles ~32 concurrent, target 25 for headroom
      clampMin: '0'
      clampMax: '500'
      operationOverTime: 'last_one'
  - type: kedify-otel
    name: waiting
    metadata:
      scalerAddress: 'kedify-otel-scaler.keda.svc:4318'
      metricQuery: 'sum(vllm_num_requests_waiting)'
      targetValue: '5'        # Scale when 5+ requests waiting (queue building)
      clampMin: '0'
      clampMax: '500'
      operationOverTime: 'last_one'
  advanced:
    scalingModifiers:
      # Formula: running requests + (waiting * 10) to heavily weight queue buildup
      # This triggers scaling proactively when queue starts building
      formula: "running + (waiting * 10)"
      target: "25"            # Target per pod (matches running targetValue)
      activationTarget: "5"   # Activate scaling when combined metric > 5
    horizontalPodAutoscalerConfig:
      behavior:
        scaleDown:
          stabilizationWindowSeconds: 300
          policies:
          - type: Percent
            value: 50
            periodSeconds: 60
        scaleUp:
          stabilizationWindowSeconds: 0   # No stabilization delay
          policies:
          - type: Percent
            value: 900        # Allow 900% increase per period (1→10 pods)
            periodSeconds: 15 # Every 15 seconds
          - type: Pods
            value: 9          # Or add up to 9 pods per period (1→10)
            periodSeconds: 15
          selectPolicy: Max
